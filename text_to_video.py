import streamlit as st
import os
import requests
import base64
from dotenv import load_dotenv
from PIL import Image
import io
from gtts import gTTS
from moviepy.editor import *
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
import tempfile
import re
import time
import json
from googletrans import Translator
import zhipuai
import numpy as np
import google.generativeai as genai
from io import BytesIO

# Download NLTK data
nltk.download('punkt')

# Load environment variables
load_dotenv()

# API Endpoints and Keys
COGVIEW_API_KEY = os.getenv('COGVIEW_API_KEY')
zhipuai.api_key = COGVIEW_API_KEY
SD_API_ENDPOINT = "https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image"
SD_API_KEYS = os.getenv('SD_API_KEYS', '').split(',')
SD_API_KEYS = [key.strip() for key in SD_API_KEYS if key.strip()]
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '')

# C·∫•u h√¨nh Gemini API
genai.configure(api_key=GEMINI_API_KEY)

class StoryContext:
    def __init__(self):
        self.characters = {}  # L∆∞u tr·ªØ th√¥ng tin nh√¢n v·∫≠t
        self.locations = {}   # L∆∞u tr·ªØ th√¥ng tin ƒë·ªãa ƒëi·ªÉm
        self.current_scene = None  # Th√¥ng tin c·∫£nh hi·ªán t·∫°i
        self.style_prompt = ""  # Prompt v·ªÅ phong c√°ch nh·∫•t qu√°n
        self.last_scene_description = ""  # M√¥ t·∫£ c·∫£nh tr∆∞·ªõc ƒë√≥
        self.character_first_descriptions = {}  # L∆∞u m√¥ t·∫£ ƒë·∫ßu ti√™n c·ªßa nh√¢n v·∫≠t
        self.scene_history = []  # L·ªãch s·ª≠ c√°c c·∫£nh
        
    def extract_entities(self, text):
        """Tr√≠ch xu·∫•t nh√¢n v·∫≠t v√† ƒë·ªãa ƒëi·ªÉm t·ª´ vƒÉn b·∫£n"""
        words = word_tokenize(text)
        
        # T√¨m c√°c c·ª•m t·ª´ vi·∫øt hoa c√≥ th·ªÉ l√† t√™n ri√™ng
        i = 0
        while i < len(words):
            word = words[i]
            if word[0].isupper() and (i > 0 or len(word) > 1):
                # K·∫øt h·ª£p c√°c t·ª´ vi·∫øt hoa li√™n ti·∫øp
                name_parts = [word]
                j = i + 1
                while j < len(words) and words[j][0].isupper():
                    name_parts.append(words[j])
                    j += 1
                
                name = " ".join(name_parts)
                
                # T√¨m m√¥ t·∫£ xung quanh nh√¢n v·∫≠t
                context_start = max(0, i - 5)
                context_end = min(len(words), j + 5)
                context = " ".join(words[context_start:context_end])
                
                if name not in self.characters:
                    # L∆∞u th√¥ng tin nh√¢n v·∫≠t l·∫ßn ƒë·∫ßu xu·∫•t hi·ªán
                    self.characters[name] = {
                        "first_appearance": text,
                        "first_context": context,
                        "description": self._extract_character_description(context),
                        "count": 1,
                        "scenes": [len(self.scene_history)]
                    }
                    self.character_first_descriptions[name] = self._extract_character_description(context)
                else:
                    self.characters[name]["count"] += 1
                    self.characters[name]["scenes"].append(len(self.scene_history))
                
                i = j
            else:
                i += 1
    
    def _extract_character_description(self, context):
        """Tr√≠ch xu·∫•t m√¥ t·∫£ nh√¢n v·∫≠t t·ª´ context"""
        # T√¨m c√°c t·ª´ m√¥ t·∫£ xung quanh nh√¢n v·∫≠t
        description_keywords = ["l√†", "c√≥", "m·∫∑c", "tu·ªïi", "cao", "tr√¥ng", "nh∆∞", "gi·ªëng"]
        description = ""
        
        for keyword in description_keywords:
            if keyword in context.lower():
                # L·∫•y ph·∫ßn vƒÉn b·∫£n sau keyword
                parts = context.lower().split(keyword)
                if len(parts) > 1:
                    # L·∫•y t·ªëi ƒëa 10 t·ª´ sau keyword
                    desc = " ".join(parts[1].split()[:10])
                    if desc:
                        description += f"{keyword} {desc}. "
        
        return description.strip()
    
    def update_scene(self, text):
        """C·∫≠p nh·∫≠t th√¥ng tin c·∫£nh hi·ªán t·∫°i"""
        self.last_scene_description = self.current_scene or ""
        self.current_scene = text
        self.scene_history.append(text)
        self.extract_entities(text)
    
    def get_character_descriptions(self):
        """T·∫°o m√¥ t·∫£ v·ªÅ nh√¢n v·∫≠t cho prompt"""
        descriptions = []
        for char, info in self.characters.items():
            if info["count"] > 0:
                # S·ª≠ d·ª•ng m√¥ t·∫£ ƒë·∫ßu ti√™n c·ªßa nh√¢n v·∫≠t
                first_desc = self.character_first_descriptions.get(char, "")
                if first_desc:
                    descriptions.append(f"character {char} ({first_desc})")
                else:
                    descriptions.append(f"character {char}")
        return ", ".join(descriptions)
    
    def get_scene_continuity(self):
        """T·∫°o m√¥ t·∫£ v·ªÅ t√≠nh li√™n t·ª•c c·ªßa c·∫£nh"""
        if len(self.scene_history) > 0:
            # L·∫•y 2 c·∫£nh g·∫ßn nh·∫•t ƒë·ªÉ tham chi·∫øu
            recent_scenes = self.scene_history[-2:] if len(self.scene_history) >= 2 else self.scene_history
            return f"maintain visual continuity with previous scenes: {' | '.join(recent_scenes)}"
        return ""

def split_text_into_scenes(text):
    """Split text into scenes based on sentences and paragraphs"""
    # Split into sentences
    sentences = sent_tokenize(text)
    
    # Group sentences into scenes (3-4 sentences per scene)
    scenes = []
    current_scene = []
    
    for sentence in sentences:
        current_scene.append(sentence)
        if len(current_scene) >= 3:
            scenes.append(' '.join(current_scene))
            current_scene = []
    
    # Add remaining sentences
    if current_scene:
        scenes.append(' '.join(current_scene))
    
    return scenes

def translate_to_chinese(text):
    """Translate text to Chinese using Google Translate API"""
    translator = Translator()
    try:
        result = translator.translate(text, dest='zh-cn')
        return result.text
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ d·ªãch sang ti·∫øng Trung: {str(e)}")
        return text

def translate_to_english(text):
    """Translate text to English using Google Translate API"""
    translator = Translator()
    try:
        result = translator.translate(text, dest='en')
        return result.text
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ d·ªãch sang ti·∫øng Anh: {str(e)}")
        return text

def generate_consistent_prompt(scene_text, story_context, style, model="stable-diffusion"):
    """T·∫°o prompt ng·∫Øn g·ªçn v√† hi·ªáu qu·∫£"""
    # C·∫≠p nh·∫≠t context v·ªõi c·∫£nh hi·ªán t·∫°i
    story_context.update_scene(scene_text)
    
    # X√°c ƒë·ªãnh nh√¢n v·∫≠t ch√≠nh trong c·∫£nh hi·ªán t·∫°i
    current_characters = []
    for char, info in story_context.characters.items():
        if len(story_context.scene_history) - 1 in info["scenes"]:
            desc = story_context.character_first_descriptions.get(char, "").strip()
            if desc:
                current_characters.append(f"{char} ({desc})")
            else:
                current_characters.append(char)
    
    # T·∫°o base prompt d·ª±a tr√™n model
    if model == "cogview":
        base_prompt = f"""Âú∫ÊôØ: {scene_text}
‰∫∫Áâ©: {', '.join(current_characters)}
È£éÊ†º: {style}È£éÊ†º, È´òÊ∏ÖÁªÜËäÇ, ÁîµÂΩ±Á∫ßÁîªÈù¢"""
        return base_prompt
    else:
        # T·∫°o prompt ng·∫Øn g·ªçn cho Stable Diffusion
        scene_desc = translate_to_english(scene_text)
        chars = ', '.join(current_characters)
        
        prompt = f"A {style} style scene: {scene_desc}. "
        if chars:
            prompt += f"Featuring {chars}. "
        
        # Th√™m y√™u c·∫ßu ch·∫•t l∆∞·ª£ng
        prompt += "High quality, detailed, cinematic composition, professional lighting."
        
        return prompt

def generate_image_cogview(prompt, style="realistic"):
    """Generate image using CogView API"""
    style_cn = {
        "realistic": "ÂÜôÂÆûÈ£éÊ†º",
        "anime": "Âä®Êº´È£éÊ†º",
        "digital art": "Êï∞Â≠óËâ∫ÊúØ",
        "oil painting": "Ê≤πÁîªÈ£éÊ†º",
        "watercolor": "Ê∞¥ÂΩ©ÁîªÈ£éÊ†º",
        "pencil sketch": "ÈìÖÁ¨îÁ¥†Êèè",
        "3D render": "3DÊ∏≤Êüì",
        "pixel art": "ÂÉèÁ¥†Ëâ∫ÊúØ",
        "comic book": "Êº´ÁîªÈ£éÊ†º"
    }
    
    enhanced_prompt = f"{style_cn.get(style, 'ÂÜôÂÆûÈ£éÊ†º')}, {prompt}, È´òË¥®Èáè"
    
    try:
        response = zhipuai.model_api.invoke(
            model="cogview-3-plus",
            prompt=enhanced_prompt,
            timeout=60
        )
        
        if not isinstance(response, dict):
            raise Exception(f"Invalid response format: {response}")
            
        if response.get('code') != 200 or not response.get('success'):
            error_msg = response.get('msg', 'Unknown error')
            raise Exception(f"CogView API Error: {error_msg}")
        
        data = response.get('data', {})
        if not isinstance(data, dict):
            raise Exception(f"Invalid data format: {data}")
            
        image_links = data.get('image_links', [])
        if not image_links or not isinstance(image_links, list):
            raise Exception(f"No image links received: {data}")
        
        image_url = image_links[0].get('url')
        if not image_url:
            raise Exception("Invalid image URL")
        
        image_response = requests.get(image_url, timeout=30)
        if image_response.status_code != 200:
            raise Exception(f"Failed to download image: HTTP {image_response.status_code}")
        
        return Image.open(io.BytesIO(image_response.content))
        
    except Exception as e:
        st.error(f"CogView API Debug Info:")
        st.error(f"Prompt: {enhanced_prompt}")
        if 'response' in locals():
            st.error(f"Response: {response}")
        raise Exception(f"CogView Error: {str(e)}")

def generate_image_sd(prompt, style="realistic", api_key=None):
    """Generate image using Stable Diffusion API with multiple keys"""
    if not api_key:
        api_key = SD_API_KEYS[0]
    
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "text_prompts": [
            {
                "text": prompt,
                "weight": 1
            },
            {
                "text": "blurry, low quality, worst quality, text, watermark, signature, deformed, distorted, disfigured, bad anatomy",
                "weight": -1
            }
        ],
        "cfg_scale": 7,
        "height": 1024,
        "width": 1024,
        "samples": 1,
        "steps": 30,
        "seed": st.session_state.get('last_seed', 42)
    }
    
    try:
        response = requests.post(
            SD_API_ENDPOINT,
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"Stable Diffusion API Error: {response.text}")
        
        result = response.json()
        
        if "artifacts" in result and len(result["artifacts"]) > 0:
            if 'seed' in result["artifacts"][0]:
                st.session_state['last_seed'] = result["artifacts"][0]['seed']
            
            image_data = result["artifacts"][0]["base64"]
            return Image.open(io.BytesIO(base64.b64decode(image_data)))
        
        raise Exception("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu h√¨nh ·∫£nh t·ª´ API")
        
    except requests.exceptions.Timeout:
        raise Exception("API ph·∫£n h·ªìi qu√° ch·∫≠m, vui l√≤ng th·ª≠ l·∫°i")
    except requests.exceptions.RequestException as e:
        raise Exception(f"L·ªói k·∫øt n·ªëi: {str(e)}")

def generate_image_gemini_colab(prompt, style="realistic"):
    """Generate image using Gemini API through Google Colab"""
    try:
        # URL c·ªßa Colab Notebook ƒë∆∞·ª£c expose qua ngrok
        COLAB_API_URL = os.getenv('COLAB_API_URL', '')
        if not COLAB_API_URL:
            raise Exception("Ch∆∞a c·∫•u h√¨nh COLAB_API_URL. Vui l√≤ng c·∫≠p nh·∫≠t trong file .env")

        # T·∫°o prompt v·ªõi style
        enhanced_prompt = f"Create a {style} style image: {prompt}. High quality, detailed, professional lighting and composition."
        
        # Chu·∫©n b·ªã payload
        payload = {
            "prompt": enhanced_prompt,
            "api_key": GEMINI_API_KEY,
            "style": style
        }
        
        # G·ªçi API c·ªßa Colab notebook
        st.info("üîÑ ƒêang k·∫øt n·ªëi v·ªõi Google Colab...")
        response = requests.post(
            COLAB_API_URL + "/generate_image",
            json=payload,
            timeout=60
        )
        
        # Ki·ªÉm tra response
        if response.status_code != 200:
            raise Exception(f"Colab API Error: {response.text}")
            
        # Parse response
        result = response.json()
        if "error" in result:
            raise Exception(f"Colab Error: {result['error']}")
            
        # L·∫•y ·∫£nh t·ª´ base64 string
        if "image" not in result:
            raise Exception("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu h√¨nh ·∫£nh t·ª´ Colab")
            
        image_data = base64.b64decode(result["image"])
        return Image.open(BytesIO(image_data))
            
    except Exception as e:
        error_msg = str(e)
        st.error("Gemini Colab API Debug Info:")
        st.error(f"Error message: {error_msg}")
        st.error(f"Prompt used: {enhanced_prompt}")
        
        # H·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën th·ª≠ l·∫°i v·ªõi model kh√°c kh√¥ng
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîÑ Th·ª≠ l·∫°i v·ªõi Stable Diffusion"):
                return generate_image_sd(prompt, style, SD_API_KEYS[0])
        with col2:
            if st.button("üîÑ Th·ª≠ l·∫°i v·ªõi CogView"):
                return generate_image_cogview(prompt, style)
        
        raise Exception(f"Gemini Colab Error: {error_msg}")

def generate_image(prompt, style, model="stable-diffusion"):
    """Generate image using selected model"""
    max_retries = 3
    current_try = 0
    last_error = None
    
    while current_try < max_retries:
        try:
            if model == "cogview":
                return generate_image_cogview(prompt, style)
            elif model == "gemini":
                return generate_image_gemini_colab(prompt, style)
            else:
                # Th·ª≠ v·ªõi t·∫•t c·∫£ API key c·ªßa Stable Diffusion
                for i, api_key in enumerate(SD_API_KEYS):
                    try:
                        return generate_image_sd(prompt, style, api_key)
                    except Exception as e:
                        if "insufficient_balance" in str(e):
                            if i < len(SD_API_KEYS) - 1:
                                st.warning(f"API key {i+1} h·∫øt balance, ƒëang th·ª≠ v·ªõi key ti·∫øp theo...")
                                continue
                            else:
                                st.warning("ƒê√£ h·∫øt t·∫•t c·∫£ API key c·ªßa Stable Diffusion, chuy·ªÉn sang s·ª≠ d·ª•ng CogView...")
                                return generate_image_cogview(prompt, style)
                        else:
                            raise e
                
                # N·∫øu ƒë√£ th·ª≠ h·∫øt c√°c key m√† v·∫´n kh√¥ng th√†nh c√¥ng
                st.warning("Kh√¥ng th·ªÉ s·ª≠ d·ª•ng Stable Diffusion, chuy·ªÉn sang CogView...")
                return generate_image_cogview(prompt, style)
                
        except Exception as e:
            last_error = e
            current_try += 1
            if current_try < max_retries:
                st.warning(f"L·∫ßn th·ª≠ {current_try} th·∫•t b·∫°i. ƒêang th·ª≠ l·∫°i...")
                time.sleep(2)  # ƒê·ª£i 2 gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i
    
    raise last_error

def text_to_speech(text, lang='vi'):
    """Convert text to speech using gTTS"""
    tts = gTTS(text=text, lang=lang, slow=False)
    audio_file = tempfile.NamedTemporaryFile(suffix='.mp3', delete=False)
    tts.save(audio_file.name)
    return audio_file.name

def create_scene_clip(image, audio_path, duration):
    """Create a video clip from image and audio"""
    image_clip = ImageClip(np.array(image)).set_duration(duration)
    audio_clip = AudioFileClip(audio_path)
    return image_clip.set_audio(audio_clip)

def create_video(scenes, images, audio_files, output_path):
    """Create final video from scenes, images and audio"""
    clips = []
    
    for image, audio_path in zip(images, audio_files):
        # Get audio duration
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        audio_clip.close()
        
        # Create scene clip
        clip = create_scene_clip(image, audio_path, duration)
        clips.append(clip)
    
    # Concatenate all clips
    final_clip = concatenate_videoclips(clips)
    
    # Write final video
    final_clip.write_videofile(
        output_path,
        fps=24,
        codec='libx264',
        audio_codec='aac'
    )
    
    # Clean up clips
    final_clip.close()
    for clip in clips:
        clip.close()

def main():
    st.set_page_config(
        page_title="Text to Video Generator",
        page_icon="üé¨",
        layout="wide"
    )
    
    # Kh·ªüi t·∫°o story context trong session state
    if 'story_context' not in st.session_state:
        st.session_state.story_context = StoryContext()
    
    st.title("üé¨ T·∫°o Video T·ª´ VƒÉn B·∫£n")
    st.write("T·∫£i l√™n file vƒÉn b·∫£n ƒë·ªÉ t·∫°o video v·ªõi h√¨nh ·∫£nh v√† gi·ªçng ƒë·ªçc")
    
    # API Key management
    with st.expander("Qu·∫£n l√Ω API Keys", expanded=False):
        st.markdown("""
        ### üìù H∆∞·ªõng d·∫´n
        - **Stable Diffusion**: Nh·∫≠p m·ªói API key tr√™n m·ªôt d√≤ng
        - **CogView**: Nh·∫≠p API key t·ª´ Zhipu AI
        - **Gemini**: Nh·∫≠p API key t·ª´ Google AI Studio
        """)
        
        # T·∫°o 3 tab cho 3 lo·∫°i API key
        tab1, tab2, tab3 = st.tabs(["üé® Stable Diffusion", "üñº CogView", "ü§ñ Gemini"])
        
        with tab1:
            # Load l·∫°i API keys t·ª´ file .env
            load_dotenv(override=True)
            current_sd_keys = os.getenv('SD_API_KEYS', '').split(',')
            current_sd_keys = [key.strip() for key in current_sd_keys if key.strip()]
            
            st.markdown("#### Stable Diffusion API Keys")
            sd_keys_input = st.text_area(
                "Nh·∫≠p c√°c API key, m·ªói key m·ªôt d√≤ng",
                value='\n'.join(current_sd_keys),
                help="M·ªói key n√™n ƒë∆∞·ª£c nh·∫≠p tr√™n m·ªôt d√≤ng m·ªõi",
                key="sd_keys",
                height=150
            )
            st.caption("S·ªë l∆∞·ª£ng key hi·ªán t·∫°i: " + str(len(current_sd_keys)))
        
        with tab2:
            current_cogview_key = os.getenv('COGVIEW_API_KEY', '')
            
            st.markdown("#### CogView API Key")
            cogview_key_input = st.text_input(
                "Nh·∫≠p API key",
                value=current_cogview_key,
                help="Nh·∫≠p CogView API key t·ª´ Zhipu AI",
                key="cogview_key",
                type="password"
            )
            if current_cogview_key:
                st.caption("‚úÖ ƒê√£ c·∫•u h√¨nh")
            else:
                st.caption("‚ùå Ch∆∞a c·∫•u h√¨nh")
        
        with tab3:
            current_gemini_key = os.getenv('GEMINI_API_KEY', '')
            
            st.markdown("#### Gemini API Key")
            st.markdown("""
            ƒê·ªÉ l·∫•y Gemini API key:
            1. Truy c·∫≠p [Google AI Studio](https://makersuite.google.com/app/apikey)
            2. ƒêƒÉng nh·∫≠p v√† t·∫°o API key m·ªõi
            3. Copy v√† d√°n API key v√†o √¥ b√™n d∆∞·ªõi
            """)
            gemini_key_input = st.text_input(
                "Nh·∫≠p API key",
                value=current_gemini_key,
                help="Nh·∫≠p Gemini API key t·ª´ Google AI Studio",
                key="gemini_key",
                type="password"
            )
            if current_gemini_key:
                st.caption("‚úÖ ƒê√£ c·∫•u h√¨nh")
            else:
                st.caption("‚ùå Ch∆∞a c·∫•u h√¨nh")
        
        # N√∫t l∆∞u
        if st.button("üíæ L∆∞u T·∫•t C·∫£ API Keys"):
            try:
                # X·ª≠ l√Ω v√† l√†m s·∫°ch input
                sd_keys = [key.strip() for key in sd_keys_input.strip().split('\n') if key.strip()]
                cogview_key = cogview_key_input.strip()
                gemini_key = gemini_key_input.strip()
                
                # C·∫≠p nh·∫≠t file .env
                with open('.env', 'w', encoding='utf-8') as f:
                    f.write(f"SD_API_KEYS={','.join(sd_keys)}\n")
                    f.write(f"COGVIEW_API_KEY={cogview_key}\n")
                    f.write(f"GEMINI_API_KEY={gemini_key}")
                
                # Reload environment variables
                load_dotenv(override=True)
                
                # C·∫≠p nh·∫≠t bi·∫øn trong ch∆∞∆°ng tr√¨nh
                global SD_API_KEYS, COGVIEW_API_KEY, GEMINI_API_KEY
                SD_API_KEYS = sd_keys
                COGVIEW_API_KEY = cogview_key
                zhipuai.api_key = cogview_key
                GEMINI_API_KEY = gemini_key
                
                # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng
                st.success("‚úÖ ƒê√£ l∆∞u t·∫•t c·∫£ API keys!")
                
                # Hi·ªÉn th·ªã chi ti·∫øt
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.info(f"üìä Stable Diffusion: {len(sd_keys)} key(s)")
                with col2:
                    st.info("üîë CogView: " + ("ƒê√£ c·∫•u h√¨nh" if cogview_key else "Ch∆∞a c·∫•u h√¨nh"))
                with col3:
                    st.info("üîë Gemini: " + ("ƒê√£ c·∫•u h√¨nh" if gemini_key else "Ch∆∞a c·∫•u h√¨nh"))
                
            except Exception as e:
                st.error(f"‚ùå L·ªói khi l∆∞u API keys: {str(e)}")
    
    # Text input
    text_file = st.file_uploader("T·∫£i l√™n file vƒÉn b·∫£n", type=['txt'])
    
    # Style and model selection
    col1, col2 = st.columns(2)
    
    with col1:
        style = st.selectbox(
            "Ch·ªçn phong c√°ch h√¨nh ·∫£nh",
            ["realistic", "anime", "digital art", "oil painting", "watercolor", 
             "pencil sketch", "3D render", "pixel art", "comic book"]
        )
    
    with col2:
        model = st.selectbox(
            "Ch·ªçn model t·∫°o h√¨nh ·∫£nh",
            ["stable-diffusion", "cogview", "gemini"],
            help="""
            - Stable Diffusion: Cho k·∫øt qu·∫£ t·ªët v√† ·ªïn ƒë·ªãnh
            - CogView: Ph√π h·ª£p v·ªõi n·ªôi dung ti·∫øng Trung
            - Gemini: API m·ªõi t·ª´ Google (ƒëang th·ª≠ nghi·ªám)
            """
        )
        
        # Hi·ªÉn th·ªã c·∫£nh b√°o n·∫øu ch·ªçn Gemini
        if model == "gemini":
            st.info("‚ÑπÔ∏è Gemini API ƒëang trong giai ƒëo·∫°n th·ª≠ nghi·ªám. N·∫øu g·∫∑p l·ªói, h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông chuy·ªÉn sang Stable Diffusion.")
            
            # Ki·ªÉm tra API server
            try:
                api_url = os.getenv('COLAB_API_URL', 'http://localhost:5000')
                response = requests.get(api_url)
                if response.status_code == 200:
                    server_info = response.json()
                    if server_info.get('status') == 'running':
                        st.success("‚úÖ ƒê√£ k·∫øt n·ªëi t·ªõi Gemini API server")
                    else:
                        st.error("‚ùå Gemini API server kh√¥ng ho·∫°t ƒë·ªông ƒë√∫ng")
                else:
                    st.error("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi Gemini API server. Vui l√≤ng ch·∫°y file gemini_image_api.py")
            except Exception as e:
                st.error(f"‚ùå L·ªói k·∫øt n·ªëi t·ªõi Gemini API server: {str(e)}")
                st.error("Vui l√≤ng ch·∫°y file gemini_image_api.py trong terminal kh√°c")
    
    if text_file:
        text_content = text_file.read().decode('utf-8')
        
        # Process button
        if st.button("T·∫°o Video"):
            try:
                # Reset story context
                st.session_state.story_context = StoryContext()
                
                # Split text into scenes
                scenes = split_text_into_scenes(text_content)
                
                # Hi·ªÉn th·ªã th√¥ng tin c·∫£nh
                st.subheader("1. Ph√¢n t√≠ch vƒÉn b·∫£n")
                with st.expander("Chi ti·∫øt c√°c c·∫£nh", expanded=True):
                    for i, scene in enumerate(scenes, 1):
                        st.markdown(f"**C·∫£nh {i}:**")
                        st.write(scene)
                
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Generate images with consistency
                images = []
                audio_files = []
                current_sd_key_index = 0
                
                # Container cho k·∫øt qu·∫£ x·ª≠ l√Ω
                result_container = st.container()
                
                for i, scene in enumerate(scenes):
                    with result_container.expander(f"ƒêang x·ª≠ l√Ω c·∫£nh {i+1}/{len(scenes)}", expanded=True):
                        status_text.text(f"ƒêang x·ª≠ l√Ω c·∫£nh {i+1}/{len(scenes)}")
                        progress = (i) / len(scenes)
                        progress_bar.progress(progress)
                        
                        # Generate prompt
                        prompt = generate_consistent_prompt(
                            scene, 
                            st.session_state.story_context,
                            style,
                            model
                        )
                        
                        st.markdown("**Prompt ƒë∆∞·ª£c t·∫°o:**")
                        st.code(prompt)
                        
                        # Th·ª≠ t·∫°o h√¨nh ·∫£nh v·ªõi c·∫£ hai model
                        success = False
                        error_messages = []
                        
                        with st.spinner("ƒêang t·∫°o h√¨nh ·∫£nh..."):
                            try:
                                image = generate_image(prompt, style, model)
                                st.success(f"‚úÖ ƒê√£ t·∫°o h√¨nh ·∫£nh th√†nh c√¥ng")
                                st.image(image, use_column_width=True)
                                images.append(image)
                                success = True
                            except Exception as e:
                                error_messages.append(str(e))
                                st.error(f"‚ùå Kh√¥ng th·ªÉ t·∫°o h√¨nh ·∫£nh: {str(e)}")
                        
                        if not success:
                            raise Exception(f"Kh√¥ng th·ªÉ t·∫°o h√¨nh ·∫£nh cho c·∫£nh {i+1}. L·ªói: {'; '.join(error_messages)}")
                        
                        # Generate audio
                        with st.spinner("ƒêang t·∫°o gi·ªçng ƒë·ªçc..."):
                            audio_file = text_to_speech(scene)
                            audio_files.append(audio_file)
                            st.success("‚úÖ ƒê√£ t·∫°o gi·ªçng ƒë·ªçc")
                            st.audio(audio_file)
                        
                        # Update progress
                        progress = (i + 1) / len(scenes)
                        progress_bar.progress(progress)
                
                # Create and save video
                with st.spinner('ƒêang t·∫°o video...'):
                    output_path = "output_video.mp4"
                    create_video(scenes, images, audio_files, output_path)
                    
                    # Display results
                    st.success("‚úÖ ƒê√£ t·∫°o video th√†nh c√¥ng!")
                    st.video(output_path)
                    
                    # Provide download link
                    with open(output_path, 'rb') as f:
                        st.download_button(
                            label="T·∫£i video xu·ªëng",
                            data=f.read(),
                            file_name="story_video.mp4",
                            mime="video/mp4"
                        )
                
                # Clean up
                for audio_file in audio_files:
                    os.unlink(audio_file)
                os.unlink(output_path)
                
            except Exception as e:
                st.error(f"L·ªói trong qu√° tr√¨nh t·∫°o video: {str(e)}")
                if 'error_messages' in locals():
                    st.error("Chi ti·∫øt l·ªói:")
                    for msg in error_messages:
                        st.error(msg)

if __name__ == "__main__":
    main() 